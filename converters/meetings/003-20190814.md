# Wednesday Aug 14, 2019 at 9:00am-10:00am PST
* online: https://ibm.webex.com/join/chhuang
* call-in: 1-844-531-0958, 927 169 571 #

## Agenda
* Greetings! 
* Discussion topics
    * Review converter definition and list
    * Review ONNX training spec and discuss how to support it in converters
    * Review findings in general converter reporting/dashboard 
    * Discuss contributor list
    * Collect pain points, desired features, new discussion topics from all converters
        * Unsupported data types
        * Unsupported optional attributes
        * Lack of tests
        * Unclear logic or explanation for the meaning of operator
        * Experimental operators

## Attendees 
* Chin Huang (onnx-tf, IBM)
* Guenther Schmuelling (tf-onnx, Microsoft)
* Winnie Tsang (onnx-tf, IBM)
* Svetlana Levitan (IBM)
* Emma Ning (mltools, Microsoft)
* Akin Solomon (Snapdragon, Qualcomm)
* Spandan Tiwari (pytorch, Microsoft)
* Saurabh Tangri (Onnx runtime, Intel)

## Notes
* Agreed the converter definition "An ONNX converter is a software component that converts models from a ML/DNN framework to the ONNX format, or vice versa", therefore we considered the backend that takes an ONNX model and executes in specific platforms as a "runtime".
* Reviewed the list of converters and runtimes and will move Windows ML and SNPE(Qualcomm) to the runtime list. The definition and list are documented at https://github.com/onnx/sigs/blob/master/converters/docs/ConvertersList.md
* Reviewed the ONNX training proposal. Chin shared the prototype code, https://github.com/chinhuang007/onnx-tf-training, that starts from a pytorch model, going through an ONNX format with training data, and ends with additional training in Tensorflow. More investigation is needed to ensure the feasibility of producing the ONNX training data from different frameworks.
* Winnie shared the proposed content and look-and-feel to make clear the operator coverage for a converter, up to each ONNX opset level. General feedback is pretty good for backend converters but not seemingly useful for frontend converters. A few points: there are so many operators (800+ for ex in tf), tiresome to go through a big table might be easier to try a model and see if fails, hard to automate the generation of coverage table, so many high level APIs translating to low level ops. We will continue the discussion next time.
* Reviewed and agreed the recommendation for handling unsupported data types in a more flexible approach with an optional user input and logging for clarity whenauto-cast is applied.

## Action items
* 1: Guenther, Spandan: investigate the feasibility of supporting ONNX training from tf and pytorch to ONNX
* 2: Chin: finalize general doc to clarify "converter" and list of converters
* 3: Winnie: continue to investigate the converter reporting/dashboard
* 4. Chin, Guenther: prepare for the workshop breakout session
