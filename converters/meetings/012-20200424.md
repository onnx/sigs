# Friday Apr 24, 2020 10:30-11:30am PST
* https://zoom.us/j/7376656864

## Agenda
* Greetings! 
* Discussion topics
    * Converters project updates
    * ONNX release 1.7
    * Training updates
    * ML operators support
    * Resize operator review

## Attendees 
* Chin Huang (onnx-tf, IBM)
* Guenther Schmuelling (tf-onnx, Microsoft)
* Kevin Chen (Nvidia)
* Winnie Tsang (onnx-tf, IBM)
* Ting Su (MathWorks)
* Svetlana Levitan (IBM)
* Sree Vaddi

## Notes
* ONNX-TF converter: still working on TF 2.0 native support, will look into training soon, spec driven development
* TF-ONNX converter: has TF 2.0 mostly working, fixing a lstm bug now
* MatLab converters: increase converage, facing challenges in change number of dimensions for inputs and outputs, for ex. gather, flatten, reshape, model case driven development
* Tensor-RT converter: having to deal with new IR version and dynamic shapes, for ex resize operator. models in model zoo not updated with recent opset version. 
* ONNX 1.7 IR version=7 in onnx file would cause problems in ONNX runtime. The frontend converters need to have a mapping to set IR version based on the opset version
* ONNX traininig is waiting for release 1.7 to add new features, including differentialable tag which is fixed per operator, utility APIs which can be used by frontend converters to provide minimum information to turn a inference model into a trainable model.
* Training support polls at ONNX Workshop indicate 30% converters will have near term support.
* Training support in the context of converters means 1. convert a framework training model to onnx 2. take onnx training model and continue training in a framework according to what is described in onnx file.
* Why onnx traininng? 1. training can be part of deployment, fine-tuning 2. optimized runtime for training 3. training with different hardware
* Keras to ONNX converter supports standard Keras APIs like layers and should take TF saved model format as well. TF-ONNX converts Keras models too, based on the graph in hd5 format, not Keras layers APIs.
* ONNX ML support polls at ONNX Workshop indicates 40% converters support some ML operators. Tensor-RT and MatLab have no plans to support in the near future. SK learn to ONNX has complete support. ONNX is faster than SK learn so no backend converter for SK learn. ONNX-Tf in investigation. General question, what is the use cases and benfits to convert ML to framework?
* Resize opset11 has a lot of attributes and complicated logic, very hard for backend converters to convert using framework APIs. ONNX-TF can only do partial support. MatLab will check with developers and share findings in next meeting. Tensor-R has own implementation, partial support certain modes, common modes: asymmetric, half_pixel, pytorch_half_pixel.
* Any unsupported ops or flavors, Tensor-RT falls back to ONNX runtime for graph partitioning. Still get performance gains from Tensor-RT. Kevein to share how it works in next meeting.
