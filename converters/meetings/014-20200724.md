# Friday July 24, 2020 10:30-11:30am PST
* https://zoom.us/j/7376656864

## Agenda
* Greetings! 
* Discussion topics
    * Converters project updates
    * Optional inputs and outputs (Clip)
    * Scalar vs 1D tensor of size 1
    * Bfloat16 test and support
    * Inference accuracy requirements
    * ONNX-ML unit tests
    * ONNX release dependency on converters 
    * Others

## Attendees 
* Chin Huang (onnx-tf, IBM)
* Guenther Schmuelling (tf-onnx, Microsoft)
* Winnie Tsang (onnx-tf, IBM)

## Notes
* ONNX-TF converter: release 1.6.0 is completed, supporting ONNX opset 11 and release 1.6
* Optional inputs can be specified with a blank input name, as seen in the Clip backend test. The backend runtimes and handlers should be aware of this treatment, despite uncommon in real models.
* Scalar could be a scalar or 1D tensor of size 1 in ONNX OneHot and NonMaxSuppression implementation. But the doc states scalar only. The backend runtimes and handlers need to double check with schema before doc is totally in-sync.
* bfloat16 is added to a lot of ops in opset 13. Would like to discuss how a general test could be written for all backends.
* Inference accuracy requirements could be relaxed due to backend implementations of same ops might produce slightly different results. TF-ONNX considers matching results up to decimal 5.
* ONNX_ML unit tests are not directly in ONNX. We will look into using ONNX runtime and SKLearn as references.
* ONNX release should not have dependency on converters. For 1.7, TF-ONNX needs to make sure the converter ONNX files have the matching IR number and opset number. Would be nice to have an ONNX lookup API to provide this mapping.
* Some work to support easier consumption of custom ops is underway. Would like to see it as an official ONNX project so broader community can benefit.
