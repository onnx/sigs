# Friday Nov 20, 2020 10:30-11:30am PST
* https://zoom.us/j/7376656864

## Agenda
* Greetings! 
* Discussion topics
    * Converters project updates
    * ONNX 1.8 impact/support
    * Custom ops story update?
    * ML data types and operators
    * Adding data processing to ONNX?

## Attendees 
* Chin Huang (onnx-tf, IBM)
* Guenther Schmuelling (tf-onnx, Microsoft)
* Winnie Tsang (onnx-tf, IBM)
* John Zhang (Black System)
## Notes
* TF-ONNX updates: opset 13 support by end of year, 97% of popular external models (from TF hub and Keras) successfully converted, prototype for TFLite, looking into qualized ops align with or wrap onnx ops, future version # might not match ONNX version #
* ONNX-TF updates: opset 12 support completed, release 1.7 in a week with added user options in auto data type cast and target tensor format (NCHW vs NHWC), will include the conversion results for all ONNX zoo models in next release
* Custom ops support as pluggable libraries to ONNX runtime is coming soon, as a new open source project. The idea is to provide pre-compiled so files for custom ops so the runtime doesn't need to know how to implement and optimize custom logic.
* Pytorch to ONNX converter seems a bit out-dated. Recommend to open issues in Pytorch repo. Someone is monitoring converter issues and should respond.
* Does it make sense to have the option of keeping NHWC format in onnx model, since some frameworks and devices without GPUs are channel last by nature? Suggest to open an issue in ONNX to possibly add a data format optional attribute to a list of impacted ops, and bring this topic up to the operators SIG for review and discussions.
* Support of ML data types such as map and array as model inputs and outputs is a challenge in TF-ONNX and ONNX-TF since Tensorflow doesn't have matching data types for traditional ML. However, sequences can be used in nodes and operators.
* Does it make sense to expand ONNX to cover some data processing in the future, as a few roadmap items are in this area? Data processing might include 1. traditional data ETL from db 2. data normalization, encoding, scaling for machine learning. We believe adding some data processing will help the consumption and optimization of the end-to-end machine learning process. We will continue to discuss what should be included, perhaps in a phased approach, and how to support it in converters.
