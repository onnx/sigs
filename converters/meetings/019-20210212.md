<!--- SPDX-License-Identifier: Apache-2.0 -->

# Thursday Feb 12 2021 5-6pm PST
* https://zoom.us/j/7376656864?pwd=SjdiaGdvUFFyVXM4OUxTWndYZ2Z1Zz09

## Agenda
* Greetings!
* Discussion topics
    * Converters project updates
    * Roadmap discussion

## Attendees
* Chin Huang (onnx-tf, IBM)
* Guenther Schmuelling (tf2onnx, Microsoft)
* Kevin Chen (Tensor-RT)
* Ting Su (Matlab)

## Notes
* ONNX-TF fully supports opset 13, except squeeze and unsqueeze where axes becoming an input, meaning a tensor instead list of ints. The issue is the corresponding TF APIs support only primitive types for axis.
* TF2ONNX released TFLite support, being able to convert TFLite directly to ONNX, making a pass at Hugging face models, added SentencePiece as custom op
* Tensor-RT is officially on opset 11, planning on support opset 13 within next release, working on QDQ tool
* Matlab keeps working on operators, import in two ways, 1. functional form, up to opset 13 2. layer type of model, still working on some constraints
* Would like to have Pytorch to ONNX converter updates in our SIG meetings
* Frontend roadmap items:
    * Convert from Tensorflow-js vs onnx-js? Convert from google/jax, like jax2onnx vs jax to tf + tf2onnx?
* Backend roadmap items:
    * Add NHWC option in ONNX, at the model level? input data format? and/or certain ops? Would be nice if the user of the model can easily know the data format.
    * Leverage Onnx model zoo models as standard test and verification for all backends
