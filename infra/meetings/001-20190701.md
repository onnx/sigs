<!--- SPDX-License-Identifier: Apache-2.0 -->

# Tuesday June 06, 2019 at 8:00am PST

## Agenda
* SparseTensor support in ONNX. https://github.com/onnx/onnx/pull/2019.
* Remove build dependencies on external frameworks.
* How to pick up first group of contributors.
* Merge ONNX-ML IR.

## Attendees
* Lu Fang (Facebok)
* Ke Zhang (Microsoft)
* Emad Barsoum (Microsoft)
* Darren S Crews (Intel)
* Ganesan Ramalingam (Microsoft)
* Wei-Sheng Chin (Microsoft)

## Notes
* SparseTensor design overall looks good. SparseTensor to support weights needs to be added. A sample model using SparseTensor should be added to confirm the design.
* It's agreed that the pytorch CI will be kept and it's not a "required" for merging an ONNX PR.
* It's agreed to merge ONNX-ML IR.
* Attendees will send a list of contributor candidates, which will be discussed in next meeting to have initial group of contributors.
* ONNX compilance may be checked in several parts.
    * How many operators should a runtime/framework implement so that it can claim itself ONNX compliant?
    * Model & OP level accuracy test cases should be added to ensure a runtime/framework is ONNX compliant. ONNX model zoo models may be picked up as the initial set of models for accuracy test.

## Action items
* Lu & Darren - review the SparseTensor PR.
* Rama - create sample model of using SparseTensor.
* Ke - Merge ONNX-ML IR.
