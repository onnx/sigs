# Thursday, June 30th, 2022 at 9:00am PST

## Agenda

* Infrastructure SIG updates
  * Protobuf upgrade
  * Attribute values in model IR
  * Function upgrades
  * Call for IR changes
* Proposal to include quantization information in the ONNX model
* [PR 4126](https://github.com/onnx/onnx/pull/4126): Resize
* [PR 4190](https://github.com/onnx/onnx/pull/4190): CenterCropPad
* [PR 4311](https://github.com/onnx/onnx/pull/4311): ScaledDotProductAttention
* [PR 4312](https://github.com/onnx/onnx/pull/4312): MultiHeadAttention
* Opens

## Attendees 

* Ganesan Ramalingam (Microsoft)
* George Nash (Intel)
* Jacky Chen (Microsoft)
* Joaquín Antón Guirao (Nvidia)
* Liqun Fu (Microsoft)
* Martin Croome (GreenWaves Technologies)
* Michal Karzynski (Intel)
* Przemyslaw Wysocki (Intel)
* Rodolfo Esteves (Intel)
* Scott Cyphers (Lightmatter)
* Yesha Thakkar (Microsoft)
* Yuan Yao (Nvidia)

## Notes

### Infrastructure SIG updates

#### Protobuf upgrade

One of ONNX's current requirements is Protocol Buffers in an older version (3.x), while newer versions (4.x)
are already available. This is causing some issues with downstream applications, which also have to use
older Protocol Buffers to maintain compatibility. A PR with an upgrade is being prepared, please test it.
https://github.com/onnx/onnx/pull/4242

#### Attribute values in model IR

Currently, optional attribute values are not stored in the model file, but rather form part of the operator schema.
A proposal is raised to make a change in the model intermediate representation to store these values together with the
model definition. This will allow user function definitions to be more expressive.


#### Function upgrades

A proposal is raised to extend the version converter API to upgrade user functions. Currently when converting a model from
one opset version to another, individual ops are upgraded, but the definition of a function can also change from one 
opset to another and the model converter should be able to perform this type of upgrade.

#### Call for IR changes

We plan to avoid changing the ONNX Protobuf IR definition too many times. However, we plan to change the IR due to
the attribute values mentioned above. Since a change is already planned, we could combine it with other changes.
If you have pending proposals which require IR changes, please create PRs and raise them as soon as possible.


### Proposal to include quantization information in the ONNX model

Martin Croome (GreenWaves Technologies) talked about his work with ONNX models as well as models 
in the TensorFlow Lite format.

In TF Lite models, some statistical information about each tensor is stored together with the model 
(e.g. min/max range). This makes it much easier to work with these models in cases which require quantization
or dequantization.

Martin proposes that such information could also be stored together with other tensor information (such as shapes, types)
in ONNX models. We should take the best practices from quantization and dequantization in other frameworks
(e.g. NNCF, QNNX) and standardize it in ONNX.

In many frameworks Fake Quantize operations can collect these statistics during training.

Rama mentioned that in the IR we are already able to express zero-point, etc. but no clear
guideline exists on how to use it, so it remains unutilized. If ONNX required these statistics,
it would influence converters and frameworks themselves to collect them during training.

Martin proposes to make a survey of existing linear quantize/dequantize operators across frameworks
and make recommendations how they could be standardized for ONNX. He will come back with his survey results
in September.

We discussed how we can connect Martin with other people interested in quantization. A good starting point will
be to create an issue in ONNX and mention the survey. 


###  PRs ready to merge

The following PRs which are about to be accepted were discussed:

* [PR 4126](https://github.com/onnx/onnx/pull/4126): Resize
* [PR 4190](https://github.com/onnx/onnx/pull/4190): CenterCropPad

### New PRs

The following new PRs were brought up to start their review process:

* [PR 4311](https://github.com/onnx/onnx/pull/4311): ScaledDotProductAttention
* [PR 4312](https://github.com/onnx/onnx/pull/4312): MultiHeadAttention

Please take a look. 


### Opens

Yuan Yao mentioned our Spec clarifications tracking [issue #3651](https://github.com/onnx/onnx/issues/3651)
There are multiple changes to the specification already listed there which can be implemented. 
We need volunteers to make pull request with these specification clarifications.
