# Thursday, December 1st, 2022 at 9:00am PST

## Agenda

* Infrastructure SIG updates
* ONNX release 1.13 update
* PR [#4640](https://github.com/onnx/onnx/pull/4640): Map ops
* Future directions

## Attendees

* Shubham Bhokare (Microsoft)
* Alexandre Eichenberger (IBM)
* Lucas Fischer (Dataka Lab)
* George Nash (Intel)
* Ganesan Ramalingam (Microsoft)
* Liqun Fu (Microsoft)
* Michal Karzynski (Intel)
* Przemyslaw Wysocki (Intel)
* Scott Cyphers (Lightmatter)


## Notes

### Infrastructure SIG updates

Liqun Fu presented the Infrastructure SIG update. Current work is mainly focused
on the upcoming 1.13 release. ONNX upgraded to Protobuf 3.20.2

### Upcoming release

Przemyslaw Wysocki presented the status of the upcoming ONNX release, which is
scheduled for mid-December.

### PR [#4640](https://github.com/onnx/onnx/pull/4640): Map ops 

Shubham Bhokare gave an overview of this PR, which introduces a set of primitive
ops for the Map data-structure. Map as a type-constructor was originally introduced
as part of ONNX-ML (for classical ML) and has been part of the ONNX standard,
but has not had operator support so far. This PR introduces a set of primitive
ops for the Map datatype.

The primary questions were about motivating models and example models. Shubham
said the motivation for the operators was to enable exporting ONNX models from
PyTorch, where maps are supported and used. Shubham said he would compile some
example models illustrating the use of maps and add it to the PR description.

### Future Directions

Rama talked about a couple of items as potential future work directions.

The first was about some updates to proto definition, which would be an update to the IR.
The motivation for these changes is to better support ONNX functions.

* Introducing LibProto as a top-level container for a library, containing a set
of function-definitions (FunctionProtos) would be a useful starting point to
developing reusable libraries of ONNX functions.

* Extending FunctionProto to define default-values for attribute-parameters would
be useful, as the existing operator-schema enables this too.

* Currently, ONNX functions do not have type-constraints on inputs/outputs,
while ONNX operators do support type-constraints. It would be useful to
consider the pros/cons of adding type-constraints to FunctionProto.

* Adding support for attaching source-location information to various
constructs in the ONNX proto definition (such as NodeProto, AttributeProto, etc.)
would help provide better diagnostic messages about ONNX models created from
some source.

The second topic was the possibility of supporting distributed inference using
ONNX models. Large models, whose memory requirements exceed the capacities of
single GPUs, are becoming common. In practice, both training and inference of
such models rely on using multiple GPUs. Typically, these models also make
use of collective communication ops, such as AllReduce, AllGather, Reduce,
ReduceScatter, Broadcast. (For example, see Nvidia's NCCL library.)
Extending ONNX to enable distributed inference for such models would be very
valuable.

Alexandre Eichenberger suggested that any support to enable parallelism
should take the form of declarative hints, allowing the backends to decide
the best way to realize parallelism, and that ONNX models should avoid
over-prescribing how the computation should happen. Rama responded that
ONNX, as an intermediate format, could be used for multiple purposes.
An optimizer that makes optimization decisions could use ONNX as the
output format to capture optimization decisions. Thus, there was value
in supporting both more or less prescriptive information in the model.

### Miscellaneous

Alexandre Eichenberger mentioned that the parameter naming styles
used for ONNX operators were not consistent. and that making it
consistent would help tools/infrastructure such as ONNX-MLIR.
Based on the suggestions, Alexandre to describe the issue in
[Issue 3651](https://github.com/onnx/onnx/issues/3651).




