# Thursday, February 22nd, 2024 at 9:00am PST

## Agenda

* Upcoming Release (1.16)
* [Issue 5943](https://github.com/onnx/onnx/issues/5943): Adding `output_dtype` attribute to QuantizeLinear
* [Issue 5895](https://github.com/onnx/onnx/issues/5895): QLinearAdd Op
* Operators SIG meeting schedule change


## Attendees

* Alexandre Eichenberger (IBM)
* Andreas Fehlner (TRUMPF)
* Charles Volzka (IBM)
* Ganesan Ramalingam (Microsoft)
* Yuan Yao (Nvidia)
* Gal Hubara Agam (Nvidia)


### Upcoming Release (1.16)

The next release is scheduled for late March. Code is scheduled to be frozen on Monday, the 26th. 
There are currently some build issues in CI, Charles and Liqun are investigating.

### [Issue 5943](https://github.com/onnx/onnx/issues/5943): Adding `output_dtype` attribute to QuantizeLinear

Gal Hubara Agam mentioned current challenges with the QuantizeLinear operation in specifying
output data types other than the default UINT8. Currently, users must provide a zero-point tensor
to indicate the desired output data type, leading to increased model size, computational overhead,
and difficulty in generating non-standard data types. The proposed solution is to introduce an optional 
`output_dtype` attribute to QuantizeLinear, allowing direct specification of the output data type 
without requiring a zero-point tensor. This approach supports existing data types 
(UINT8, INT8, UINT16, INT16, UINT4, INT4, FLOAT8) and maintains backward compatibility.

The discussion leaned towards agreeing with the proposal and considering its inclusion in the next release.


## [Issue 5895](https://github.com/onnx/onnx/issues/5895): QLinearAdd Op

Charles Volzka brought up the need for a standardized `QLinearAdd` operation. This operator, 
designed for quantized data, incorporates `zero_point` and `scale` input tensors for both 
input and output tensors. Although this operator is implemented in 
ONNXRuntime, it is not officially included in the ONNX standard operators. 

`QLinearAdd` is used across several INT8 ONNX models in the ONNX Model Zoo, 
where almost all models featuring `QLinearMatMul` also utilize `QLinearAdd`. 
However, ONNX-MLIR, committed to supporting only official ONNX operators,
faces challenges in accommodating these models due to the absence of `QLinearAdd` 
in the ONNX standard list of operators.

During discussion, it was noted that this would be a useful addition to the standard, especially
since it should be possible to express the operator as a function. We should not aim to add quantized
versions of all mathematical operations, in most cases the pattern Quantize - op - Dequantize can be used.
In this case however, since models are already using the operation, adding it would be useful. 


### Operators SIG meeting schedule change

We have decided to change the meeting schedule to the 4th Thursday of every month 
(previously the last Thursday of the month). Meetings schedule will be available on the
[LF AI & Data Foundation wiki](https://wiki.lfaidata.foundation/pages/viewpage.action?pageId=18481196).

Andreas Fehlner discussed the transition to the Linux Foundation's LFX system for scheduling meetings,
highlighting synchronization issues between LFX and Groups.io, leading to confusion and mismatches 
in meeting dates and links. To improve the situation, Andreas suggested possibly creating LFX accounts
for regular attendees, enabling direct invites from the LFX system and reducing reliance on manual 
updates.
