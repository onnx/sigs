# ONNX Operators SIG meeting
# Thursday, July 25th, 2024 at 9:00am PST

## Agenda

* Patch Release 1.16.2
* Automating the ONNX release process
* Upcoming Release 1.17
* FP4 Data Type Proposal
* Opens

## Attendees

* Andreas Fehlner (TRUMPF Laser)
* Charles Volzka (IBM)
* Gal Hubara Agam (Nvidia)
* Ganesan Ramalingam (Microsoft)
* Justin Chu (Microsoft)
* Liqun Fu (Microsoft)
* Raghavan Naresh (Intel)
* Sunny Anand (IBM)
* Yuan Yao (Nvidia)

## Meeting minutes

### Patch Release 1.16.2

Plans for a potential patch release 1.16.2 were discussed. 
The main focus was on addressing a recently opened CVE that affects version 1.16.1 of ONNX. 
Considering that the 1.17 release may still be a number of weeks off, it was recommended that a 1.16.2 patch 
release to fix the CVE would be beneficial. 
The discussion highlighted a problem with the current build process caused by the recent release of Numpy 2.0.
A workaround for the build problems was proposed, and it was agreed that we should proceed with the patch release.

### Automating the ONNX release process

Andreas Fehlner proposed introducing an automated workflow to the ONNX release process.
The proposed workflow includes creating Python wheels for different operating systems, as well
as a source distribution file. Once the artifacts are built, they can be published automatically
to PyPI, which would significantly reduce the amount of manual work for an ONNX release manager.
Automating this process also reduces the potential for errors and increases security.
The weekly release workflow can be fully automated, but the official release workflow should require
a manual trigger. Discussions about how this should be handled are ongoing in GitHub 
[issue #6246](https://github.com/onnx/onnx/issues/6246).

It was agreed that while the proposal is beneficial, it is complex and should not be rushed
into the upcoming 1.17 release. Instead, it should be targeted for a later release, possibly 1.18,
to ensure thorough testing and refinement. Andreas invited others to collaborate and provide feedback.

### Upcoming Release 1.17

Raghavan Naresh from Intel will take on the role of release manager for the upcoming ONNX release 1.17.
Naresh already started preparing for the release process, addressing key tasks such as testing and uploading packages.
The team reviewed the open pull requests and milestones, deciding to focus on resolving priority PRs
while deferring some to future releases.

### FP4 Data Type Proposal

Yuan Yao from Nvidia shared a presentation of a proposal to add FP4 as a new data type to ONNX.
Motivation comes from computational requirements of deploying large language models (LLMs).
Narrow precision data types are becoming increasingly popular in this area due to their efficiency.

Yuan presented the S1E2M1 floating point data type with a range of -6 to 6 and discussed
conversions between FP4 and other data types. 

To add FP4 to ONNX, the following steps are necessary: integrate FP4 S1E2M1 into the ONNX proto, 
introduce a custom non-numpy type for FP4, implement support for packing and unpacking FP4 data, 
and extend relevant operators to handle FP4. This includes updating Cast, QuantizeLinear, DequantizeLinear,
and non-compute operations like Const and Shape.

The S1E2M1 is a good candidate for FP4 and currently the main focus of the Open Compute Project's 
Microscaling Formats Specification. It was agreed that it would be beneficial to add it to ONNX.

### Opens

Gal Agam raised a question about the open [PR #6124](https://github.com/onnx/onnx/pull/6124) related to
refactoring custom types, including INT4. Justin Chu explained that the PR aimed to improve performance 
by replacing slow Python map functions with more efficient methods. He recommended proceeding with FP4-related 
PRs without waiting for this refactoring PR to be merged, but suggested leveraging useful patterns from it if possible. 
